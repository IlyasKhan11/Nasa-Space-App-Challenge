{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c4d896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d9d43a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>CANDIDATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>CONFIRMED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_period  koi_duration  koi_depth  koi_prad  koi_teq  koi_insol  \\\n",
       "0    9.488036       2.95750      615.8      2.26    793.0      93.59   \n",
       "1   54.418383       4.50700      874.8      2.83    443.0       9.11   \n",
       "2   19.899140       1.78220    10829.0     14.60    638.0      39.30   \n",
       "3    1.736952       2.40641     8079.2     33.46   1395.0     891.96   \n",
       "4    2.525592       1.65450      603.3      2.75   1406.0     926.16   \n",
       "\n",
       "   koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0           35.8              0              0              0              0   \n",
       "1           25.8              0              0              0              0   \n",
       "2           76.3              0              0              0              0   \n",
       "3          505.6              0              1              0              0   \n",
       "4           40.9              0              0              0              0   \n",
       "\n",
       "   koi_steff  koi_slogg  koi_srad  koi_kepmag koi_disposition  \n",
       "0     5455.0      4.467     0.927      15.347       CONFIRMED  \n",
       "1     5455.0      4.467     0.927      15.347       CONFIRMED  \n",
       "2     5853.0      4.544     0.868      15.436       CANDIDATE  \n",
       "3     5805.0      4.564     0.791      15.597  FALSE POSITIVE  \n",
       "4     6031.0      4.438     1.046      15.509       CONFIRMED  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('data/df_KOI_NOT_Capped.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd51a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['koi_disposition'] = data['koi_disposition'].map({\n",
    "    'FALSE POSITIVE': 0,\n",
    "    'CANDIDATE': 1,\n",
    "    'CONFIRMED': 2\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43ae844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('koi_disposition', axis=1)\n",
    "y=data['koi_disposition']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b483339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9.564000e+03</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9.564000e+03</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.671358</td>\n",
       "      <td>5.621606</td>\n",
       "      <td>2.290432e+04</td>\n",
       "      <td>99.077250</td>\n",
       "      <td>1077.514534</td>\n",
       "      <td>7.490517e+03</td>\n",
       "      <td>250.903691</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.232748</td>\n",
       "      <td>0.197512</td>\n",
       "      <td>0.120033</td>\n",
       "      <td>5709.107277</td>\n",
       "      <td>4.315009</td>\n",
       "      <td>1.701053</td>\n",
       "      <td>14.264633</td>\n",
       "      <td>0.781159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1334.744046</td>\n",
       "      <td>6.471554</td>\n",
       "      <td>8.079020e+04</td>\n",
       "      <td>3018.723391</td>\n",
       "      <td>840.875323</td>\n",
       "      <td>1.565158e+05</td>\n",
       "      <td>781.868222</td>\n",
       "      <td>4.767290</td>\n",
       "      <td>0.422605</td>\n",
       "      <td>0.398142</td>\n",
       "      <td>0.325018</td>\n",
       "      <td>781.672343</td>\n",
       "      <td>0.425019</td>\n",
       "      <td>6.011383</td>\n",
       "      <td>1.385378</td>\n",
       "      <td>0.863287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>6.966000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.733684</td>\n",
       "      <td>2.437750</td>\n",
       "      <td>1.668000e+02</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>2.216000e+01</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5333.000000</td>\n",
       "      <td>4.232750</td>\n",
       "      <td>0.835750</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.752831</td>\n",
       "      <td>3.792600</td>\n",
       "      <td>4.211000e+02</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>1.416000e+02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.520000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.715178</td>\n",
       "      <td>6.276500</td>\n",
       "      <td>1.341775e+03</td>\n",
       "      <td>13.112500</td>\n",
       "      <td>1352.500000</td>\n",
       "      <td>8.067975e+02</td>\n",
       "      <td>71.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6099.000000</td>\n",
       "      <td>4.539000</td>\n",
       "      <td>1.313000</td>\n",
       "      <td>15.322000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129995.778400</td>\n",
       "      <td>138.540000</td>\n",
       "      <td>1.541400e+06</td>\n",
       "      <td>200346.000000</td>\n",
       "      <td>14667.000000</td>\n",
       "      <td>1.094755e+07</td>\n",
       "      <td>9054.700000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15896.000000</td>\n",
       "      <td>5.364000</td>\n",
       "      <td>229.908000</td>\n",
       "      <td>20.003000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          koi_period  koi_duration     koi_depth       koi_prad       koi_teq  \\\n",
       "count    9564.000000   9564.000000  9.564000e+03    9564.000000   9564.000000   \n",
       "mean       75.671358      5.621606  2.290432e+04      99.077250   1077.514534   \n",
       "std      1334.744046      6.471554  8.079020e+04    3018.723391    840.875323   \n",
       "min         0.241843      0.052000  0.000000e+00       0.080000     25.000000   \n",
       "25%         2.733684      2.437750  1.668000e+02       1.430000    553.000000   \n",
       "50%         9.752831      3.792600  4.211000e+02       2.390000    878.000000   \n",
       "75%        40.715178      6.276500  1.341775e+03      13.112500   1352.500000   \n",
       "max    129995.778400    138.540000  1.541400e+06  200346.000000  14667.000000   \n",
       "\n",
       "          koi_insol  koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "count  9.564000e+03    9564.000000    9564.000000    9564.000000   \n",
       "mean   7.490517e+03     250.903691       0.208595       0.232748   \n",
       "std    1.565158e+05     781.868222       4.767290       0.422605   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    2.216000e+01      12.300000       0.000000       0.000000   \n",
       "50%    1.416000e+02      23.000000       0.000000       0.000000   \n",
       "75%    8.067975e+02      71.125000       0.000000       0.000000   \n",
       "max    1.094755e+07    9054.700000     465.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_co  koi_fpflag_ec     koi_steff    koi_slogg     koi_srad  \\\n",
       "count    9564.000000    9564.000000   9564.000000  9564.000000  9564.000000   \n",
       "mean        0.197512       0.120033   5709.107277     4.315009     1.701053   \n",
       "std         0.398142       0.325018    781.672343     0.425019     6.011383   \n",
       "min         0.000000       0.000000   2661.000000     0.047000     0.109000   \n",
       "25%         0.000000       0.000000   5333.000000     4.232750     0.835750   \n",
       "50%         0.000000       0.000000   5767.000000     4.438000     1.000000   \n",
       "75%         0.000000       0.000000   6099.000000     4.539000     1.313000   \n",
       "max         1.000000       1.000000  15896.000000     5.364000   229.908000   \n",
       "\n",
       "        koi_kepmag  koi_disposition  \n",
       "count  9564.000000      9564.000000  \n",
       "mean     14.264633         0.781159  \n",
       "std       1.385378         0.863287  \n",
       "min       6.966000         0.000000  \n",
       "25%      13.440000         0.000000  \n",
       "50%      14.520000         0.000000  \n",
       "75%      15.322000         2.000000  \n",
       "max      20.003000         2.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f60b1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff608d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 3. Transform test data (DON'T fit again!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "779f604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f354b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Training Random Forest...\n",
      "✅ Random Forest Results:\n",
      "Accuracy:  0.9080\n",
      "Precision: 0.8831\n",
      "Recall:    0.8780\n",
      "F1-Score:  0.8802\n",
      "Best Params: {'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "[[922  14   3]\n",
      " [ 14 309  82]\n",
      " [  7  56 506]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       939\n",
      "           1       0.82      0.76      0.79       405\n",
      "           2       0.86      0.89      0.87       569\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.88      0.88      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "🔧 Training Decision Tree...\n",
      "✅ Decision Tree Results:\n",
      "Accuracy:  0.8949\n",
      "Precision: 0.8643\n",
      "Recall:    0.8589\n",
      "F1-Score:  0.8607\n",
      "Best Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}\n",
      "[[922  14   3]\n",
      " [  9 290 106]\n",
      " [  4  65 500]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.79      0.72      0.75       405\n",
      "           2       0.82      0.88      0.85       569\n",
      "\n",
      "    accuracy                           0.89      1913\n",
      "   macro avg       0.86      0.86      0.86      1913\n",
      "weighted avg       0.89      0.89      0.89      1913\n",
      "\n",
      "\n",
      "🔧 Training Gradient Boosting...\n",
      "✅ Gradient Boosting Results:\n",
      "Accuracy:  0.9106\n",
      "Precision: 0.8853\n",
      "Recall:    0.8819\n",
      "F1-Score:  0.8830\n",
      "Best Params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
      "[[919  17   3]\n",
      " [  5 310  90]\n",
      " [  5  51 513]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.82      0.77      0.79       405\n",
      "           2       0.85      0.90      0.87       569\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.89      0.88      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "🔧 Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Results:\n",
      "Accuracy:  0.6357\n",
      "Precision: 0.5564\n",
      "Recall:    0.5578\n",
      "F1-Score:  0.5306\n",
      "Best Params: {'C': 10.0, 'solver': 'lbfgs'}\n",
      "[[723  73 143]\n",
      " [144  52 209]\n",
      " [115  13 441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.77      0.75       939\n",
      "           1       0.38      0.13      0.19       405\n",
      "           2       0.56      0.78      0.65       569\n",
      "\n",
      "    accuracy                           0.64      1913\n",
      "   macro avg       0.56      0.56      0.53      1913\n",
      "weighted avg       0.61      0.64      0.60      1913\n",
      "\n",
      "\n",
      "🔧 Training AdaBoost...\n",
      "✅ AdaBoost Results:\n",
      "Accuracy:  0.8813\n",
      "Precision: 0.8480\n",
      "Recall:    0.8410\n",
      "F1-Score:  0.8427\n",
      "Best Params: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "[[917  13   9]\n",
      " [  2 274 129]\n",
      " [  5  69 495]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.77      0.68      0.72       405\n",
      "           2       0.78      0.87      0.82       569\n",
      "\n",
      "    accuracy                           0.88      1913\n",
      "   macro avg       0.85      0.84      0.84      1913\n",
      "weighted avg       0.88      0.88      0.88      1913\n",
      "\n",
      "\n",
      "🔧 Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:36] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:38] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:39] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:40] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:42] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:43] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:44] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [22:10:48] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBoost Results:\n",
      "Accuracy:  0.9090\n",
      "Precision: 0.8826\n",
      "Recall:    0.8799\n",
      "F1-Score:  0.8809\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "[[921  16   2]\n",
      " [  7 311  87]\n",
      " [  5  57 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       939\n",
      "           1       0.81      0.77      0.79       405\n",
      "           2       0.85      0.89      0.87       569\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.88      0.88      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "🏆 Best Model: GradientBoostingClassifier with Accuracy: 0.9106\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier  # <-- Step 1: Import\n",
    "\n",
    "# === Define Models & Hyperparameters ===\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)  # <-- Step 2: Add model\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 20],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 5]\n",
    "    },\n",
    "\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 1.0]\n",
    "    },\n",
    "\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "\n",
    "    \"XGBoost\": {  # <-- Step 3: Add hyperparameters\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Train and Evaluate ===\n",
    "best_model = None\n",
    "best_score = 0\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔧 Training {name}...\")\n",
    "    grid = GridSearchCV(model, params[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"✅ {name} Results:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model_scores[name] = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'best_params': grid.best_params_\n",
    "    }\n",
    "\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "# === Save Best Model ===\n",
    "print(f\"\\n🏆 Best Model: {type(best_model).__name__} with Accuracy: {best_score:.4f}\")\n",
    "pickle.dump(best_model, open(\"best_model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef69a070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 2, 1, 0], shape=(1913,))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c72ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp=scaler.transform(data.head(2).drop('koi_disposition', axis=1))\n",
    "result=best_model.predict(inp)\n",
    "result[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085f684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda0573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e28e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
