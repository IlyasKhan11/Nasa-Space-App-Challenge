{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4d896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d9d43a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_prad_log</th>\n",
       "      <th>koi_depth_log</th>\n",
       "      <th>koi_teq_log</th>\n",
       "      <th>koi_insol_log</th>\n",
       "      <th>koi_model_snr_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1.181727</td>\n",
       "      <td>6.424545</td>\n",
       "      <td>6.677083</td>\n",
       "      <td>4.549552</td>\n",
       "      <td>3.605498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1.342865</td>\n",
       "      <td>6.775138</td>\n",
       "      <td>6.095825</td>\n",
       "      <td>2.313525</td>\n",
       "      <td>3.288402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>2.747271</td>\n",
       "      <td>9.290075</td>\n",
       "      <td>6.459904</td>\n",
       "      <td>3.696351</td>\n",
       "      <td>4.347694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>3.539799</td>\n",
       "      <td>8.997172</td>\n",
       "      <td>7.241366</td>\n",
       "      <td>6.794542</td>\n",
       "      <td>6.227722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>6.404071</td>\n",
       "      <td>7.249215</td>\n",
       "      <td>6.832126</td>\n",
       "      <td>3.735286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_period  koi_duration  koi_depth  koi_prad  koi_teq  koi_insol  \\\n",
       "0    9.488036       2.95750      615.8      2.26    793.0      93.59   \n",
       "1   54.418383       4.50700      874.8      2.83    443.0       9.11   \n",
       "2   19.899140       1.78220    10829.0     14.60    638.0      39.30   \n",
       "3    1.736952       2.40641     8079.2     33.46   1395.0     891.96   \n",
       "4    2.525592       1.65450      603.3      2.75   1406.0     926.16   \n",
       "\n",
       "   koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0           35.8              0              0              0              0   \n",
       "1           25.8              0              0              0              0   \n",
       "2           76.3              0              0              0              0   \n",
       "3          505.6              0              1              0              0   \n",
       "4           40.9              0              0              0              0   \n",
       "\n",
       "   koi_steff  koi_slogg  koi_srad  koi_kepmag koi_disposition  koi_prad_log  \\\n",
       "0     5455.0      4.467     0.927      15.347       CONFIRMED      1.181727   \n",
       "1     5455.0      4.467     0.927      15.347       CONFIRMED      1.342865   \n",
       "2     5853.0      4.544     0.868      15.436       CANDIDATE      2.747271   \n",
       "3     5805.0      4.564     0.791      15.597  FALSE POSITIVE      3.539799   \n",
       "4     6031.0      4.438     1.046      15.509       CONFIRMED      1.321756   \n",
       "\n",
       "   koi_depth_log  koi_teq_log  koi_insol_log  koi_model_snr_log  \n",
       "0       6.424545     6.677083       4.549552           3.605498  \n",
       "1       6.775138     6.095825       2.313525           3.288402  \n",
       "2       9.290075     6.459904       3.696351           4.347694  \n",
       "3       8.997172     7.241366       6.794542           6.227722  \n",
       "4       6.404071     7.249215       6.832126           3.735286  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('data/df_KOI_full_outliers.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f40bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_period', 'koi_duration', 'koi_depth', 'koi_prad', 'koi_teq',\n",
       "       'koi_insol', 'koi_model_snr', 'koi_fpflag_nt', 'koi_fpflag_ss',\n",
       "       'koi_fpflag_co', 'koi_fpflag_ec', 'koi_steff', 'koi_slogg', 'koi_srad',\n",
       "       'koi_kepmag', 'koi_disposition', 'koi_prad_log', 'koi_depth_log',\n",
       "       'koi_teq_log', 'koi_insol_log', 'koi_model_snr_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd51a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['koi_disposition'] = data['koi_disposition'].map({\n",
    "    'FALSE POSITIVE': 0,\n",
    "    'CANDIDATE': 1,\n",
    "    'CONFIRMED': 2\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ae844e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_prad_log</th>\n",
       "      <th>koi_depth_log</th>\n",
       "      <th>koi_teq_log</th>\n",
       "      <th>koi_insol_log</th>\n",
       "      <th>koi_model_snr_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>1.181727</td>\n",
       "      <td>6.424545</td>\n",
       "      <td>6.677083</td>\n",
       "      <td>4.549552</td>\n",
       "      <td>3.605498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>1.342865</td>\n",
       "      <td>6.775138</td>\n",
       "      <td>6.095825</td>\n",
       "      <td>2.313525</td>\n",
       "      <td>3.288402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>2.747271</td>\n",
       "      <td>9.290075</td>\n",
       "      <td>6.459904</td>\n",
       "      <td>3.696351</td>\n",
       "      <td>4.347694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>3.539799</td>\n",
       "      <td>8.997172</td>\n",
       "      <td>7.241366</td>\n",
       "      <td>6.794542</td>\n",
       "      <td>6.227722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>1.321756</td>\n",
       "      <td>6.404071</td>\n",
       "      <td>7.249215</td>\n",
       "      <td>6.832126</td>\n",
       "      <td>3.735286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>0.527699</td>\n",
       "      <td>3.22210</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.903</td>\n",
       "      <td>14.082</td>\n",
       "      <td>3.412797</td>\n",
       "      <td>7.365307</td>\n",
       "      <td>7.644441</td>\n",
       "      <td>8.412173</td>\n",
       "      <td>6.118758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>1.739849</td>\n",
       "      <td>3.11400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6119.0</td>\n",
       "      <td>4.444</td>\n",
       "      <td>1.031</td>\n",
       "      <td>14.757</td>\n",
       "      <td>0.542324</td>\n",
       "      <td>3.901973</td>\n",
       "      <td>7.383368</td>\n",
       "      <td>7.369481</td>\n",
       "      <td>2.451005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>0.681402</td>\n",
       "      <td>0.86500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6173.0</td>\n",
       "      <td>4.447</td>\n",
       "      <td>1.041</td>\n",
       "      <td>15.385</td>\n",
       "      <td>0.727549</td>\n",
       "      <td>4.650144</td>\n",
       "      <td>7.704812</td>\n",
       "      <td>8.650746</td>\n",
       "      <td>2.587764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>333.486169</td>\n",
       "      <td>3.19900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4989.0</td>\n",
       "      <td>2.992</td>\n",
       "      <td>7.824</td>\n",
       "      <td>10.998</td>\n",
       "      <td>3.010621</td>\n",
       "      <td>6.461624</td>\n",
       "      <td>6.324359</td>\n",
       "      <td>3.164631</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>4.856035</td>\n",
       "      <td>3.07800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1.193</td>\n",
       "      <td>14.826</td>\n",
       "      <td>0.717840</td>\n",
       "      <td>4.352855</td>\n",
       "      <td>7.144407</td>\n",
       "      <td>6.410865</td>\n",
       "      <td>2.219203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9563 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_period  koi_duration  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0       9.488036       2.95750              0              0              0   \n",
       "1      54.418383       4.50700              0              0              0   \n",
       "2      19.899140       1.78220              0              0              0   \n",
       "3       1.736952       2.40641              0              1              0   \n",
       "4       2.525592       1.65450              0              0              0   \n",
       "...          ...           ...            ...            ...            ...   \n",
       "9558    0.527699       3.22210              0              1              1   \n",
       "9559    1.739849       3.11400              0              0              0   \n",
       "9560    0.681402       0.86500              0              0              1   \n",
       "9561  333.486169       3.19900              0              0              0   \n",
       "9562    4.856035       3.07800              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_steff  koi_slogg  koi_srad  koi_kepmag  koi_prad_log  \\\n",
       "0                 0     5455.0      4.467     0.927      15.347      1.181727   \n",
       "1                 0     5455.0      4.467     0.927      15.347      1.342865   \n",
       "2                 0     5853.0      4.544     0.868      15.436      2.747271   \n",
       "3                 0     5805.0      4.564     0.791      15.597      3.539799   \n",
       "4                 0     6031.0      4.438     1.046      15.509      1.321756   \n",
       "...             ...        ...        ...       ...         ...           ...   \n",
       "9558              0     5638.0      4.529     0.903      14.082      3.412797   \n",
       "9559              0     6119.0      4.444     1.031      14.757      0.542324   \n",
       "9560              0     6173.0      4.447     1.041      15.385      0.727549   \n",
       "9561              0     4989.0      2.992     7.824      10.998      3.010621   \n",
       "9562              1     6469.0      4.385     1.193      14.826      0.717840   \n",
       "\n",
       "      koi_depth_log  koi_teq_log  koi_insol_log  koi_model_snr_log  \n",
       "0          6.424545     6.677083       4.549552           3.605498  \n",
       "1          6.775138     6.095825       2.313525           3.288402  \n",
       "2          9.290075     6.459904       3.696351           4.347694  \n",
       "3          8.997172     7.241366       6.794542           6.227722  \n",
       "4          6.404071     7.249215       6.832126           3.735286  \n",
       "...             ...          ...            ...                ...  \n",
       "9558       7.365307     7.644441       8.412173           6.118758  \n",
       "9559       3.901973     7.383368       7.369481           2.451005  \n",
       "9560       4.650144     7.704812       8.650746           2.587764  \n",
       "9561       6.461624     6.324359       3.164631           2.708050  \n",
       "9562       4.352855     7.144407       6.410865           2.219203  \n",
       "\n",
       "[9563 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define target\n",
    "target_col = \"koi_disposition\"\n",
    "\n",
    "# Original cols to drop (since log versions exist)\n",
    "orig_cols = [\"koi_prad\", \"koi_depth\", \"koi_teq\", \n",
    "             \"koi_insol\", \"koi_model_snr\"]\n",
    "\n",
    "# Build feature matrix and target\n",
    "X = data.drop(columns=[target_col] + orig_cols)\n",
    "y = data[target_col]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b483339d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_prad_log</th>\n",
       "      <th>koi_depth_log</th>\n",
       "      <th>koi_teq_log</th>\n",
       "      <th>koi_insol_log</th>\n",
       "      <th>koi_model_snr_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9.563000e+03</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9.563000e+03</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.677541</td>\n",
       "      <td>5.621791</td>\n",
       "      <td>2.290664e+04</td>\n",
       "      <td>99.087369</td>\n",
       "      <td>1077.563317</td>\n",
       "      <td>7.491296e+03</td>\n",
       "      <td>250.926153</td>\n",
       "      <td>0.159992</td>\n",
       "      <td>0.232772</td>\n",
       "      <td>0.197532</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>5709.158946</td>\n",
       "      <td>4.314988</td>\n",
       "      <td>1.701141</td>\n",
       "      <td>14.264589</td>\n",
       "      <td>0.781031</td>\n",
       "      <td>1.822796</td>\n",
       "      <td>6.625411</td>\n",
       "      <td>6.753558</td>\n",
       "      <td>4.959849</td>\n",
       "      <td>3.705344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1334.813701</td>\n",
       "      <td>6.471867</td>\n",
       "      <td>8.079410e+04</td>\n",
       "      <td>3018.881075</td>\n",
       "      <td>840.905757</td>\n",
       "      <td>1.565240e+05</td>\n",
       "      <td>781.906019</td>\n",
       "      <td>0.366617</td>\n",
       "      <td>0.422620</td>\n",
       "      <td>0.398158</td>\n",
       "      <td>0.325032</td>\n",
       "      <td>781.696883</td>\n",
       "      <td>0.425036</td>\n",
       "      <td>6.011691</td>\n",
       "      <td>1.385444</td>\n",
       "      <td>0.863242</td>\n",
       "      <td>1.369629</td>\n",
       "      <td>2.316183</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>2.559853</td>\n",
       "      <td>1.579078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2661.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>6.966000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.733379</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>1.668000e+02</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>2.215000e+01</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5333.500000</td>\n",
       "      <td>4.232500</td>\n",
       "      <td>0.835500</td>\n",
       "      <td>13.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>5.122773</td>\n",
       "      <td>6.317165</td>\n",
       "      <td>3.141994</td>\n",
       "      <td>2.587764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.751921</td>\n",
       "      <td>3.792200</td>\n",
       "      <td>4.211000e+02</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>1.416000e+02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.220830</td>\n",
       "      <td>6.045242</td>\n",
       "      <td>6.778785</td>\n",
       "      <td>4.960044</td>\n",
       "      <td>3.178054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.715305</td>\n",
       "      <td>6.277000</td>\n",
       "      <td>1.342550e+03</td>\n",
       "      <td>13.115000</td>\n",
       "      <td>1353.000000</td>\n",
       "      <td>8.069550e+02</td>\n",
       "      <td>71.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6099.000000</td>\n",
       "      <td>4.539000</td>\n",
       "      <td>1.313000</td>\n",
       "      <td>15.322000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.647238</td>\n",
       "      <td>7.203070</td>\n",
       "      <td>7.210818</td>\n",
       "      <td>6.694506</td>\n",
       "      <td>4.278747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129995.778400</td>\n",
       "      <td>138.540000</td>\n",
       "      <td>1.541400e+06</td>\n",
       "      <td>200346.000000</td>\n",
       "      <td>14667.000000</td>\n",
       "      <td>1.094755e+07</td>\n",
       "      <td>9054.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15896.000000</td>\n",
       "      <td>5.364000</td>\n",
       "      <td>229.908000</td>\n",
       "      <td>20.003000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.207806</td>\n",
       "      <td>14.248202</td>\n",
       "      <td>9.593424</td>\n",
       "      <td>16.208627</td>\n",
       "      <td>9.111150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          koi_period  koi_duration     koi_depth       koi_prad       koi_teq  \\\n",
       "count    9563.000000   9563.000000  9.563000e+03    9563.000000   9563.000000   \n",
       "mean       75.677541      5.621791  2.290664e+04      99.087369   1077.563317   \n",
       "std      1334.813701      6.471867  8.079410e+04    3018.881075    840.905757   \n",
       "min         0.241843      0.052000  0.000000e+00       0.080000     25.000000   \n",
       "25%         2.733379      2.437500  1.668000e+02       1.430000    553.000000   \n",
       "50%         9.751921      3.792200  4.211000e+02       2.390000    878.000000   \n",
       "75%        40.715305      6.277000  1.342550e+03      13.115000   1353.000000   \n",
       "max    129995.778400    138.540000  1.541400e+06  200346.000000  14667.000000   \n",
       "\n",
       "          koi_insol  koi_model_snr  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "count  9.563000e+03    9563.000000    9563.000000    9563.000000   \n",
       "mean   7.491296e+03     250.926153       0.159992       0.232772   \n",
       "std    1.565240e+05     781.906019       0.366617       0.422620   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    2.215000e+01      12.300000       0.000000       0.000000   \n",
       "50%    1.416000e+02      23.000000       0.000000       0.000000   \n",
       "75%    8.069550e+02      71.150000       0.000000       0.000000   \n",
       "max    1.094755e+07    9054.700000       1.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_co  koi_fpflag_ec     koi_steff    koi_slogg     koi_srad  \\\n",
       "count    9563.000000    9563.000000   9563.000000  9563.000000  9563.000000   \n",
       "mean        0.197532       0.120046   5709.158946     4.314988     1.701141   \n",
       "std         0.398158       0.325032    781.696883     0.425036     6.011691   \n",
       "min         0.000000       0.000000   2661.000000     0.047000     0.109000   \n",
       "25%         0.000000       0.000000   5333.500000     4.232500     0.835500   \n",
       "50%         0.000000       0.000000   5767.000000     4.438000     1.000000   \n",
       "75%         0.000000       0.000000   6099.000000     4.539000     1.313000   \n",
       "max         1.000000       1.000000  15896.000000     5.364000   229.908000   \n",
       "\n",
       "        koi_kepmag  koi_disposition  koi_prad_log  koi_depth_log  koi_teq_log  \\\n",
       "count  9563.000000      9563.000000   9563.000000    9563.000000  9563.000000   \n",
       "mean     14.264589         0.781031      1.822796       6.625411     6.753558   \n",
       "std       1.385444         0.863242      1.369629       2.316183     0.680769   \n",
       "min       6.966000         0.000000      0.076961       0.000000     3.258097   \n",
       "25%      13.440000         0.000000      0.887891       5.122773     6.317165   \n",
       "50%      14.520000         0.000000      1.220830       6.045242     6.778785   \n",
       "75%      15.322000         2.000000      2.647238       7.203070     7.210818   \n",
       "max      20.003000         2.000000     12.207806      14.248202     9.593424   \n",
       "\n",
       "       koi_insol_log  koi_model_snr_log  \n",
       "count    9563.000000        9563.000000  \n",
       "mean        4.959849           3.705344  \n",
       "std         2.559853           1.579078  \n",
       "min         0.000000           0.000000  \n",
       "25%         3.141994           2.587764  \n",
       "50%         4.960044           3.178054  \n",
       "75%         6.694506           4.278747  \n",
       "max        16.208627           9.111150  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f60b1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff608d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 3. Transform test data (DON'T fit again!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pickle.dump(scaler, open(\"scaler.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779f604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f354b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Training Random Forest...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Random Forest Results:\n",
      "Accuracy:  0.9252\n",
      "Precision: 0.9018\n",
      "Recall:    0.8977\n",
      "F1-Score:  0.8996\n",
      "Best Params: {'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "[[947   9   3]\n",
      " [  9 307  66]\n",
      " [  6  50 516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       959\n",
      "           1       0.84      0.80      0.82       382\n",
      "           2       0.88      0.90      0.89       572\n",
      "\n",
      "    accuracy                           0.93      1913\n",
      "   macro avg       0.90      0.90      0.90      1913\n",
      "weighted avg       0.92      0.93      0.92      1913\n",
      "\n",
      "\n",
      "🔧 Training Decision Tree...\n",
      "✅ Decision Tree Results:\n",
      "Accuracy:  0.9090\n",
      "Precision: 0.8831\n",
      "Recall:    0.8708\n",
      "F1-Score:  0.8750\n",
      "Best Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5}\n",
      "[[944  11   4]\n",
      " [  8 274 100]\n",
      " [  6  45 521]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       959\n",
      "           1       0.83      0.72      0.77       382\n",
      "           2       0.83      0.91      0.87       572\n",
      "\n",
      "    accuracy                           0.91      1913\n",
      "   macro avg       0.88      0.87      0.88      1913\n",
      "weighted avg       0.91      0.91      0.91      1913\n",
      "\n",
      "\n",
      "🔧 Training Gradient Boosting...\n",
      "✅ Gradient Boosting Results:\n",
      "Accuracy:  0.9252\n",
      "Precision: 0.8998\n",
      "Recall:    0.9006\n",
      "F1-Score:  0.9000\n",
      "Best Params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200}\n",
      "[[940  16   3]\n",
      " [  0 311  71]\n",
      " [  5  48 519]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       959\n",
      "           1       0.83      0.81      0.82       382\n",
      "           2       0.88      0.91      0.89       572\n",
      "\n",
      "    accuracy                           0.93      1913\n",
      "   macro avg       0.90      0.90      0.90      1913\n",
      "weighted avg       0.93      0.93      0.93      1913\n",
      "\n",
      "\n",
      "🔧 Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logistic Regression Results:\n",
      "Accuracy:  0.8944\n",
      "Precision: 0.8604\n",
      "Recall:    0.8540\n",
      "F1-Score:  0.8560\n",
      "Best Params: {'C': 10.0, 'solver': 'liblinear'}\n",
      "[[940  10   9]\n",
      " [  0 269 113]\n",
      " [  5  65 502]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       959\n",
      "           1       0.78      0.70      0.74       382\n",
      "           2       0.80      0.88      0.84       572\n",
      "\n",
      "    accuracy                           0.89      1913\n",
      "   macro avg       0.86      0.85      0.86      1913\n",
      "weighted avg       0.90      0.89      0.89      1913\n",
      "\n",
      "\n",
      "🔧 Training AdaBoost...\n",
      "✅ AdaBoost Results:\n",
      "Accuracy:  0.9049\n",
      "Precision: 0.8732\n",
      "Recall:    0.8711\n",
      "F1-Score:  0.8716\n",
      "Best Params: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "[[938  15   6]\n",
      " [  0 286  96]\n",
      " [  5  60 507]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       959\n",
      "           1       0.79      0.75      0.77       382\n",
      "           2       0.83      0.89      0.86       572\n",
      "\n",
      "    accuracy                           0.90      1913\n",
      "   macro avg       0.87      0.87      0.87      1913\n",
      "weighted avg       0.91      0.90      0.90      1913\n",
      "\n",
      "\n",
      "🔧 Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:26] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:27] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:28] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:29] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:30] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:31] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:32] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:33] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:34] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:35] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/home/muhammad-ilyas-khan/anaconda3/envs/myenv/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [21:00:37] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBoost Results:\n",
      "Accuracy:  0.9279\n",
      "Precision: 0.9032\n",
      "Recall:    0.9032\n",
      "F1-Score:  0.9031\n",
      "Best Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "[[945  11   3]\n",
      " [  4 314  64]\n",
      " [  4  52 516]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       959\n",
      "           1       0.83      0.82      0.83       382\n",
      "           2       0.89      0.90      0.89       572\n",
      "\n",
      "    accuracy                           0.93      1913\n",
      "   macro avg       0.90      0.90      0.90      1913\n",
      "weighted avg       0.93      0.93      0.93      1913\n",
      "\n",
      "\n",
      "🏆 Best Model: XGBClassifier with Accuracy: 0.9279\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier  # <-- Step 1: Import\n",
    "\n",
    "# === Define Models & Hyperparameters ===\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)  # <-- Step 2: Add model\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 20],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "\n",
    "    \"Decision Tree\": {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 5]\n",
    "    },\n",
    "\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 1.0]\n",
    "    },\n",
    "\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'solver': ['lbfgs', 'liblinear']\n",
    "    },\n",
    "\n",
    "    \"XGBoost\": {  # <-- Step 3: Add hyperparameters\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}\n",
    "\n",
    "# === Train and Evaluate ===\n",
    "best_model = None\n",
    "best_score = 0\n",
    "model_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔧 Training {name}...\")\n",
    "    grid = GridSearchCV(model, params[name], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='macro')\n",
    "    rec = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"✅ {name} Results:\")\n",
    "    print(f\"Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall:    {rec:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"Best Params: {grid.best_params_}\")\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    model_scores[name] = {\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'best_params': grid.best_params_\n",
    "    }\n",
    "\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = grid.best_estimator_\n",
    "\n",
    "# === Save Best Model ===\n",
    "print(f\"\\n🏆 Best Model: {type(best_model).__name__} with Accuracy: {best_score:.4f}\")\n",
    "pickle.dump(best_model, open(\"best_model.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef69a070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, ..., 2, 0, 0], shape=(1913,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72ba01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085f684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda0573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534e28e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
